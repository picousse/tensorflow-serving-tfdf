# Introduction

TensorFlow Serving is a flexible, high-performance serving system for machine
learning models, designed for production environments. TensorFlow Serving
makes it easy to deploy new algorithms and experiments, while keeping the same
server architecture and APIs. TensorFlow Serving provides out-of-the-box
integration with TensorFlow models, but can be easily extended to serve other
types of models and data.

To get started with TensorFlow Serving:

* Read the [overview](architecture_overview.md)
* [Set up](setup.md) your environment
* Do the [basic tutorial](serving_basic.md)
* Or watch the Talk from TensorFlow Dev Summit 2017:
[![Serving Models in Production with TensorFlow Serving](https://img.youtube.com/vi/q_IkJcPyNl0/0.jpg)](http://www.youtube.com/watch?v=q_IkJcPyNl0)


![TensorFlow Serving Diagram](images/tf_diagram.svg){: width="500"}
